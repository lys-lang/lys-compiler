import support::env
import support::test
import src::lexer
import src::tokens
import src::parser

#[export]
fun test(): void = {
  START("Lexer tests")

  case1()
  case2()
  case3()
  case4()
  whitespaces()
  strings()
  parentheses()
  macroDecorations()
  singleLineComment()
  numbers()

  END()

  START("Parser tests")
  parser1()
  jsonParser()
  END()
}

fun case1(): void = {
  START("case1")

  val p = Lexer("A  BCS C DEF ghi123  ???")

  validateToken(p, Identifier, "A")
  validateToken(p, Whitespace, "  ")
  validateToken(p, Identifier, "BCS")
  validateToken(p, Whitespace, " ")
  validateToken(p, Identifier, "C")
  validateToken(p, Whitespace, " ")
  validateToken(p, Identifier, "DEF")
  validateToken(p, Whitespace, " ")
  validateToken(p, Identifier, "ghi123")
  validateToken(p, Whitespace, "  ")
  validateToken(p, Identifier, "???")
  validateToken(p, EndOfFile, "")
  validateToken(p, EndOfFile, "")

  END()
}


fun parentheses(): void = {
  {
    START("Parentheses")
    val p = Lexer("asd( ))")

    validateToken(p, Identifier, "asd")
    validateToken(p, ParenthesesOpen, "(")
    validateToken(p, Whitespace, " ")
    validateToken(p, ParenthesesClose, ")")
    validateToken(p, ParenthesesClose, ")")

    validateToken(p, EndOfFile, "")
    END()
  }

  {
    START("Curly")
    val p = Lexer("asd({}}))")

    validateToken(p, Identifier, "asd")
    validateToken(p, ParenthesesOpen, "(")
    validateToken(p, CurlyBracesOpen, "{")
    validateToken(p, CurlyBracesClose, "}")
    validateToken(p, CurlyBracesClose, "}")
    validateToken(p, ParenthesesClose, ")")
    validateToken(p, ParenthesesClose, ")")

    validateToken(p, EndOfFile, "")
    END()
  }
}

fun case2(): void = {
  START("Empty case")

  val p = Lexer("")

  validateToken(p, EndOfFile, "")
  validateToken(p, EndOfFile, "")

  END()
}

fun case3(): void = {
  START("case3")

  val p = Lexer("a  AA,, αρετη")

  validateToken(p, Identifier, "a")
  validateToken(p, Whitespace, "  ")
  validateToken(p, Identifier, "AA")
  validateToken(p, Comma, ",")
  validateToken(p, Comma, ",")
  validateToken(p, Whitespace, " ")
  validateToken(p, Identifier, "αρετη")
  validateToken(p, EndOfFile, "")

  END()
}

fun case4(): void = {
  START("case4")

  val p = Lexer("asd   AA a")

  validateToken(p, Identifier, "asd")
  validateToken(p, Whitespace, "   ")
  validateToken(p, Identifier, "AA")
  validateToken(p, Whitespace, " ")
  validateToken(p, Identifier, "a")
  validateToken(p, EndOfFile, "")

  END()
}

fun whitespaces(): void = {
  START("Whitespaces")

  val p = Lexer(" \n\r\t;")

  validateToken(p, Whitespace, " ")
  validateToken(p, NewLine, "\n\r")
  validateToken(p, Whitespace, "\t")
  validateToken(p, NewLine, ";")
  validateToken(p, EndOfFile, "")

  END()
}


fun numbers(): void = {
  START("Numbers")

  {
    val p = Lexer("1234 ")
    validateToken(p, NumberLiteral, "1234")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }

  {
    val p = Lexer("1234.131231313123123 ")
    validateToken(p, NumberLiteral, "1234.131231313123123")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }
  {
    val p = Lexer("1234.1E100 ")
    validateToken(p, NumberLiteral, "1234.1E100")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }
  {
    val p = Lexer("1234.1e100 ")
    validateToken(p, NumberLiteral, "1234.1e100")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }
  {
    val p = Lexer("1234.1e+100 ")
    validateToken(p, NumberLiteral, "1234.1e+100")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }
  {
    val p = Lexer("1234.1e-100 ")
    validateToken(p, NumberLiteral, "1234.1e-100")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }
  {
    val p = Lexer("1234.1e-100e1 ")
    validateToken(p, NumberLiteral, "1234.1e-100")
    validateToken(p, Identifier, "e1")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }
  {
    val p = Lexer("1234.1.123 ")
    validateToken(p, NumberLiteral, "1234.1")
    validateToken(p, Operator, ".")
    validateToken(p, NumberLiteral, "123")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }
  {
    val p = Lexer("0x0 ")
    validateToken(p, NumberLiteral, "0x0")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }

  {
    val p = Lexer("0xabcdef1234567890hijk ")
    validateToken(p, NumberLiteral, "0xabcdef1234567890")
    validateToken(p, Identifier, "hijk")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }

  {
    val p = Lexer("0Xabcdef1234567890hijk ")
    validateToken(p, NumberLiteral, "0Xabcdef1234567890")
    validateToken(p, Identifier, "hijk")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }

  {
    val p = Lexer("0b10010100123 ")
    validateToken(p, NumberLiteral, "0b100101001")
    validateToken(p, NumberLiteral, "23")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }
  {
    val p = Lexer("0B10010100123 ")
    validateToken(p, NumberLiteral, "0B100101001")
    validateToken(p, NumberLiteral, "23")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }

  {
    val p = Lexer("0o1234560789 ")
    validateToken(p, NumberLiteral, "0o12345607")
    validateToken(p, NumberLiteral, "89")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }

  {
    val p = Lexer("0O1234560789 ")
    validateToken(p, NumberLiteral, "0O12345607")
    validateToken(p, NumberLiteral, "89")
    validateToken(p, Whitespace, " ")
    validateToken(p, EndOfFile, "")
  }

  END()
}

fun strings(): void = {
  {
    START("Strings")
    val p = Lexer(" \"asd\" \"\"  ")

    validateToken(p, Whitespace, " ")
    validateToken(p, StringLiteral, "\"asd\"")
    validateToken(p, Whitespace, " ")
    validateToken(p, StringLiteral, "\"\"")
    validateToken(p, Whitespace, "  ")
    validateToken(p, EndOfFile, "")
    END()
  }

  {
    START("Strings with comment")
    val p = Lexer(" \"a/" ++ "/sd\" \"\"  ")

    validateToken(p, Whitespace, " ")
    validateToken(p, StringLiteral, "\"a/" ++ "/sd\"")
    validateToken(p, Whitespace, " ")
    validateToken(p, StringLiteral, "\"\"")
    validateToken(p, Whitespace, "  ")
    validateToken(p, EndOfFile, "")
    END()
  }
}


fun macroDecorations(): void = {
  START("Macro decoration")

  val p = Lexer("#[exp#ort][]")

  validateToken(p, MacroDecoration, "#[")
  validateToken(p, Identifier, "exp")
  validateToken(p, Unknown, "#")
  validateToken(p, Identifier, "ort")
  validateToken(p, VectorClose, "]")
  validateToken(p, VectorOpen, "[")
  validateToken(p, VectorClose, "]")
  validateToken(p, EndOfFile, "")

  END()
}

fun singleLineComment(): void = {
  START("Single line comment")
  {
    val p = Lexer("/"++"/ asd")

    validateToken(p, LineComment, "/"++"/ asd")
    validateToken(p, EndOfFile, "")

    END()
  }

  START("Single line comment 2")
  {
    val p = Lexer("asd /" ++ "/ asd\n  asd")

    validateToken(p, Identifier, "asd")
    validateToken(p, Whitespace, " ")
    validateToken(p, LineComment, "/" ++ "/ asd\n")
    validateToken(p, Whitespace, "  ")
    validateToken(p, Identifier, "asd")
    validateToken(p, EndOfFile, "")

    END()
  }

  START("Multi line comment")
  {
    val p = Lexer("asd /" ++ "* asd */\n  asd")

    validateToken(p, Identifier, "asd")
    validateToken(p, Whitespace, " ")
    validateToken(p, MultiLineComment, "/" ++ "* asd */")
    validateToken(p, NewLine, "\n")
    validateToken(p, Whitespace, "  ")
    validateToken(p, Identifier, "asd")
    validateToken(p, EndOfFile, "")

    END()
  }
}

fun validateToken(p: Lexer, expectedToken: TokenType, expectedValue: string): void = {
  match p.eat() {
    case is Token(tokenType, start, end) -> {
      val given = TokenType.toString(tokenType)
      val expected = TokenType.toString(expectedToken)
      mustEqual(given, expected, "eat " ++ expected ++ "(" ++ expectedValue ++ ")")
      val givenValue = p.source.substring(start as i32, end as i32)
      mustEqual(givenValue, expectedValue, "value=(" ++ expectedValue ++ ")")
    }
  }
}

fun verifyParsing(source: string, rule: string, grammar: Grammar): void = {
  START("Test parsing " ++ rule ++ " on " ++ source)

  val lexer = Lexer(source)
  val parser = Parser(lexer, grammar)
  val result = parse(rule, parser, 0)
  verify(result is AST, "Must parse into a valid result")
  printAst(result, 0)
  verify(lexer.hasNext() == false, "Lexer should have finished scanning")

  END()
}

fun testPrintAst(): void = {
  START("printAst & repeat")
  val testToken = Token(Identifier, 0x0, 0x0)

  mustEqual(repeat("1", 0), "", "test repeat * 0")
  mustEqual(repeat("1", 1), "1", "test repeat * 1")
  mustEqual(repeat("1", 2), "11", "test repeat * 2")
  mustEqual(repeat("1", 3), "111", "test repeat * 3")

  mustEqual(
    printAst(
      AstCons(
        Branch("Test1", AstCons(
          Branch("Test1.1", Leaf("Leaf1", testToken, "Hi")),
          Branch("Test1.2", Leaf("Leaf2", testToken, "Hi"))
        )),
        Branch("Test2", AstCons(
          Branch("Test2.1", Leaf("Leaf1", testToken, "Hi")),
          Branch("Test2.2", Leaf("Leaf2", testToken, "Hi"))
        ))
      )
    , 0),
    "|-Test1\n" ++
    "  |-Test1.1\n" ++
    "    |-Leaf1=Hi\n" ++
    "  |-Test1.2\n" ++
    "    |-Leaf2=Hi\n" ++
    "|-Test2\n" ++
    "  |-Test2.1\n" ++
    "    |-Leaf1=Hi\n" ++
    "  |-Test2.2\n" ++
    "    |-Leaf2=Hi",
    "test printAst"
  )
  END()
}

fun parser1(): void = {
  START("Smoke parser tests")

  testPrintAst()

  val grammar =
    Nominal("Number", Terminal(NumberLiteral)) ++
    Nominal("Operator", Terminal(Operator)) ++
    Nominal("ParenExpression",
      Cons(
        Terminal(ParenthesesOpen),
        Cons(
          NonTerminal("Equation"),
          Terminal(ParenthesesClose)
        )
      )
    ) ++
    Nominal("Equation",
      Or(NonTerminal("BinaryOperation"), NonTerminal("Term"))
    ) ++
    Nominal("BinaryOperation",
      Cons(
        NonTerminal("Term"),
        Cons(
          NonTerminal("Operator"),
          NonTerminal("Term")
        )
      )
    ) ++
    Nominal("Term",
      Or(
        NonTerminal("ParenExpression"),
        NonTerminal("Number")
      )
    )

  support::env::printf(grammar.toString())

  verify(findRule("UnexistentRule123", grammar) is Nil, "Unexistent rule must yield nil")
  verify(findRule("Term", grammar) is ParserRule, "Test find rule Term")
  verify(findRule("Equation", grammar) is ParserRule, "Test find rule Equation")
  verify(findRule("ParenExpression", grammar) is ParserRule, "Test find rule ParenExpression")
  verify(findRule("Operator", grammar) is ParserRule, "Test find rule Operator")
  verify(findRule("Number", grammar) is ParserRule, "Test find rule Number")


  START("Straight forward case for parsing")
  verifyParsing("1", "Equation", grammar)
  verifyParsing("1", "Number", grammar)
  verifyParsing("1+2", "Equation", grammar)
  END()

  START("Backtracking and pick second path")
  verifyParsing("(2+(2*123))*5332", "Equation", grammar)
  END()

  END()
}

// WS? rule WS?
fun spacedRule(rule: ParserRule): ParserRule = Cons(Optional(NonTerminal("WS")), Cons(rule, Optional(NonTerminal("WS"))))

fun jsonParser(): void = {
  START("JSON parser")

  val grammar =
    Nominal("WS", OneOrMore(Or(Terminal(Whitespace), Terminal(NewLine)))) ++
    Nominal("value",
      Or(NonTerminal("true"),
      Or(NonTerminal("false"),
      Or(NonTerminal("null"),
      Or(NonTerminal("string"),
      Or(NonTerminal("number"),
      Or(NonTerminal("object"), NonTerminal("array")))))))
    ) ++
    Nominal("false", StrictTerminal(Identifier, "false")) ++
    Nominal("true", StrictTerminal(Identifier, "true")) ++
    Nominal("null", StrictTerminal(Identifier, "null")) ++
    Nominal("string", Terminal(StringLiteral)) ++
    Nominal("number", Terminal(NumberLiteral)) ++
    Nominal("member",
      Cons(
        NonTerminal("string"),
        Cons(
          NonTerminal("COLON"),
          NonTerminal("value")
        )
      )
    ) ++
    Nominal("object",
      Cons(
        NonTerminal("OBJ_O"),
        Cons(
          Optional(
            Cons(
              NonTerminal("member"),
              ZeroOrMore(Cons(NonTerminal("COMMA"), NonTerminal("member")))
            )
          ),
          NonTerminal("OBJ_C")
        )
      )
    ) ++
    Nominal("array",
      Cons(
        NonTerminal("ARR_O"),
        Cons(
          Optional(
            Cons(
              NonTerminal("value"),
              ZeroOrMore(Cons(NonTerminal("COMMA"), NonTerminal("value")))
            )
          ),
          NonTerminal("ARR_C")
        )
      )
    ) ++
    Nominal("OBJ_O", spacedRule(Terminal(CurlyBracesOpen))) ++
    Nominal("OBJ_C", spacedRule(Terminal(CurlyBracesClose))) ++
    Nominal("ARR_O", spacedRule(Terminal(VectorOpen))) ++
    Nominal("ARR_C", spacedRule(Terminal(VectorClose))) ++
    Nominal("COLON", spacedRule(StrictTerminal(Operator, ":"))) ++
    Nominal("COMMA", spacedRule(Terminal(Comma)))

  support::env::printf(grammar.toString())

  START("Straight forward case for parsing")
  {
    verifyParsing("null", "value", grammar)
    verifyParsing("true", "value", grammar)
    verifyParsing("false", "value", grammar)
    verifyParsing("{}", "value", grammar)
    verifyParsing("[]", "value", grammar)
    verifyParsing("\"asd\"", "value", grammar)
    verifyParsing("\"\"", "value", grammar)
    verifyParsing("123.4", "value", grammar)
    verifyParsing("[1]", "value", grammar)
    verifyParsing("[1,2]", "value", grammar)
    verifyParsing("{\"a\": 1}", "value", grammar)
    verifyParsing("{\"a\": 1, \"b\": 1}", "value", grammar)
    verifyParsing("{\"a\":false,\"b\":\"asd\\n      asd \",\"list\":[1,2,3,true]}", "value", grammar)
  }
  END()

  END()
}
