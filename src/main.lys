import src::tokens
import support::ffi

struct Parser(source: string, pos: u32)
struct None()

var instance: Parser | None = None

/**
 * Updates the parser with a string.
 */
fun instantiate(str: string): void = {
  instance = Parser(str, 0 as u32)
}

#[export "parse"]
fun parse(strAddress: UnsafeCPointer): void = instantiate(UCS2.fromPtr(strAddress))

#[export "eat"]
fun externalEat(): UnsafeCPointer = eat() as UnsafeCPointer

fun eat(): string = match instance {
  case p is Parser -> {
    val tok = p.eat()
    match tok.tokenType {
      case is EndOfFile -> "EndOfFile"
      else -> TokenType.toString(tok.tokenType) ++ "(" ++ p.source.substring(tok.start as i32, tok.end as i32) ++ ")"
    }
  }
  else -> "ParserNotInitialized"
}

impl Parser {
  // Overload
  fun apply(str: string): Parser = {
    Parser(str, 0 as u32)
  }

  #[method]
  fun hasNext(self: Parser): boolean = self.pos < self.source.length

  #[method]
  fun peek(self: Parser): u32 = self.source[self.pos + 1 as u32] as u32

  #[method]
  fun head(self: Parser): u32 = self.source[self.pos] as u32

  #[method]
  fun seek(self: Parser, position: u32): void = {
    self.pos = position
  }

  #[method]
  fun next(self: Parser): u32 = {
    self.pos = self.pos + 1 as u32
    self.source[self.pos] as u32
  }

  fun tokenStart(char: u32): TokenType = match char {
    case 0x20 -> Whitespace        // space
    case 0x9  -> Whitespace        // \t
    case 0xA  -> NewLine           // \n
    case 0xD  -> NewLine           // \r
    case 0x28 -> ParenthesesOpen   // (
    case 0x29 -> ParenthesesClose  // )
    case 0x22 -> StringLiteral     // "
    case 0x24 -> Identifier        // $       '$'? [A-Za-z_]([A-Za-z0-9_$])*
    case 0x5F -> Identifier        // _       '$'? [A-Za-z_]([A-Za-z0-9_$])*
    else -> {
      if (char >= 0x41 /* A */ && char <= 0x5A /* Z */) {
        Identifier
      } else if (char >= 0x61 /* a */ && char <= 0x7a /* z */) {
        Identifier
      } else {
        Unknown
      }
    }
  }

  #[method]
  fun eat(self: Parser): Token = {
    if (self.pos == self.source.length) {
      Token(EndOfFile, self.source.length, self.source.length)
    } else {
      val eaten = match tokenStart(self.head()) {
        case is Whitespace -> eatWhitespace(self)
        case is NewLine -> eatNewLine(self)
        case is StringLiteral -> eatString(self)
        case is Identifier -> eatIdentifier(self)
        case is ParenthesesOpen -> eatSingleChar(self, ParenthesesOpen)
        case is ParenthesesClose -> eatSingleChar(self, ParenthesesClose)
        else -> eatUnknown(self)
      }
      self.seek(eaten.end)
      eaten
    }
  }

  private fun eatSingleChar(self: Parser, tokenType: TokenType): Token = {
    val start = self.pos
    var end = self.pos + 1 as u32
    Token(tokenType, start, end)
  }

  private fun eatWhitespace(self: Parser): Token = {
    val start = self.pos
    var end = self.pos
    val len = self.source.length
    loop {
      if (end >= len)
        break

      val char = self.source[end]

      if (char != 0x20)
      if (char != 0x9)
        break

      end = end + 1 as u32
      continue
    }
    Token(Whitespace, start, end)
  }

  private fun eatUnknown(self: Parser): Token = {
    val start = self.pos
    var end = self.pos
    val len = self.source.length
    loop {
      if (end >= len)
        break

      val char = self.source[end] as u32

      match tokenStart(char) {
        case is Unknown -> {
          end = end + 1 as u32
          continue
        }
        else -> break
      }
    }
    Token(Unknown, start, end)
  }

  private fun eatString(self: Parser): Token = {
    val start = self.pos
    var end = self.pos
    val len = self.source.length
    loop {
      if (end >= len)
        break

      val char = self.source[end]

      if (char == 0x22 && start != end) {
        end = end + 1 as u32
        break
      }

      end = end + 1 as u32
      continue
    }
    Token(StringLiteral, start, end)
  }

  private fun eatNewLine(self: Parser): Token = {
    val start = self.pos
    var end = self.pos
    val len = self.source.length
    loop {
      if (end >= len)
        break

      val char = self.source[end]

      if (char != 0xA)
      if (char != 0xD)
        break

      end = end + 1 as u32
      continue
    }
    Token(NewLine, start, end)
  }

  private fun eatIdentifier(self: Parser): Token = {
    val start = self.pos
    var end = self.pos
    val len = self.source.length

    // TODO: Validate first char

    loop { // [A-Za-z0-9_$]
      if (end >= len)
        break

      val char = self.source[end] as u32

      if (char != 0x24) // $
      if (char != 0x5F) // _
      if (char < 0x41 || char > 0x5A) // A-Z
      if (char < 0x61 || char > 0x7a) // a-z
      if (char < 0x30 || char > 0x39) // 0-9
        break

      end = end + 1 as u32
      continue
    }
    Token(Identifier, start, end)
  }
}
